% !TeX root = ../main.tex

\ustcsetup{
  keywords  = {高性能并行, Top-k, 国产AI处理器},
  keywords* = {High-performance parallel computing, Top-k, Domestic AI processor or China-made AI processor},
}

\begin{abstract}
  在深度学习技术蓬勃发展的浪潮中，Top-k 查询算法已深度渗透至其各个细分领域，成为众多关键任务不可或缺的核心操作环节。
  然而，深度学习模型所涉及的数据规模呈指数级增长，这使得传统的 Top-k 查询算法在应对海量数据时陷入困境，
  其效率之低难以契合当下对快速响应与精确查询的严苛需求。
  与此同时，DLP-M 系列处理器作为国产 AI 硬件架构的杰出代表，专为深度学习应用场景量身打造，具备指令集高度灵活、并行计算能力卓越以及硬件资源利
  用率出众等显著优势。遗憾的是，现有的 Top-k 查询算法，如RadixSelect，BucketSelect等算法，大多聚焦于传统 CPU 或 GPU 来进行实现和优化，
  由于体系结构和编程范式的差异，不能直接应用在 DLP-M 等国产 AI 处理器上，因此其巨大潜力还远远没有被释放。
  在此背景下，设计具备高性能并行计算能力的 Top-k 查询算子，并深度融合 DLP-M 的硬件特质以优化数据处理效能，
  已然成为当前学术研究的前沿热点与关键方向。
  
  另外，随着国家之间的科技竞争不断升级，该研究不仅能够进一步填补国产 AI 处理器在高效 Top-k 算子优化方面的空白，
  也为国产 AI 计算生态的发展提供了理论与实践支持。未来，随着国产 AI 计算体系的不断完善，
  本研究将进一步推动人工智能计算框架的本土化发展，助力自主创新与产业升级。
  鉴于此，本文基于RadixSelect算法，并紧密依托 DLP-M 的硬件特性，设计并实现了更高性能的 Top-k 算子，并在深度学习任务
  的不同场景下进行优化，充分验证了其卓越的性能优势。具体而言，本文的主要学术贡献体现如下：
  
  其一，针对大/小 k 两种差异化场景，基于 RadixSelect 算法进行深度拓展，结合 DLP-M 独特的体系结构和指令集设计并实现了 Top-k 算子，
  有效拓宽了国产 AI 处理器上 Top-k 查询方法的边界与可能性。实证研究表明，在数据量达到较大规模时，该算法相较于原有的实现方案展现出更为优异的性能表现，在效率提升方面成效斐然。
  
  其二，深度扎根于国产 AI 处理器体系架构，对 RadixSelect 并行算法展开全方位优化。通过充分发掘 DLP-M 处理器的硬件加速潜能与向量化指令优势，
  实现高效并行加速。同时，从桶操作的并行性、内存访问效率以及流水线指令等多个维度进行精细优化，
  使得算法吞吐量获得大幅跃升。在处理较大规模数据时，其性能表现已趋近甚至超越 NVIDIA A100 GPU，达到行业领先水平，为国产处理器在该领域的应用树立了新的标杆。
  
  其三，着眼于深度学习模型的实际应用需求，开展功能性验证研究。
  为切实检验算法在真实应用场景中的效果，本文精心设计了精度测试实验和性能测试实验。
  并结合 Pytorch 深度学习框架，将优化后的 Top-k 算子融入神经网络，进行训练和推理的可用性验证。
  实验数据显示，其在精度方面与基准方法维持相当水平，为深度学习任务中 Top-k 查询问题的高效解决提供了创新性的解决方案与实践路径。
  
  综上所述，本文所提出的基于 DLP-M 系列处理器的高效 Top-k 查询算法，凭借其对硬件特性的精准把握与定制化优化策略，成功实现了深度学习任务中 Top-k 操作效率的质的飞跃，为学界与业界在高效处理海量数据的 Top-k 查询问题上开辟了崭新的视野与方向，
  具有重要的理论与实践意义。 
\end{abstract}

\begin{abstract*}
  In the surging wave of the vigorous development of deep learning technology, the Top-k query algorithm has deeply permeated into various subfields of it, becoming an indispensable core operation in many key tasks.
  However, the data scale involved in deep learning models is growing exponentially. This makes traditional Top-k query algorithms fall into a predicament when dealing with massive amounts of data. Their low efficiency is difficult to meet the current stringent requirements for fast response and accurate query.
  
  At the same time, the DLP-M series processors, as outstanding representatives of domestic AI hardware architectures, are specifically designed for deep learning application scenarios. They have significant advantages such as highly flexible instruction sets, excellent parallel computing capabilities, and outstanding utilization of hardware resources. Unfortunately, most of the existing Top-k query algorithms, such as RadixSelect, BucketSelect, and other algorithms, mostly focus on traditional CPUs or GPUs for implementation and optimization. Due to differences in architecture and programming paradigms, they cannot be directly applied to domestic AI processors such as DLP-M, so their huge potential has not been fully unleashed.
  Against this backdrop, designing a Top-k query operator with high-performance parallel computing capabilities and deeply integrating the hardware characteristics of DLP-M to optimize data processing efficiency has become a cutting-edge research topic and a key direction in current academic research.
  
  In addition, with the continuous escalation of scientific and technological competition among countries, this research can not only further fill the gap in the optimization of efficient Top-k operators for domestic AI processors, but also provide theoretical and practical support for the development of the domestic AI computing ecosystem. In the future, with the continuous improvement of the domestic AI computing system, this research will further promote the localization development of artificial intelligence computing frameworks and contribute to independent innovation and industrial upgrading.
  In view of this, based on the RadixSelect algorithm and closely relying on the hardware characteristics of DLP-M, this paper designs and implements a more high-performance Top-k operator, and optimizes it in different scenarios of deep learning tasks, fully verifying its excellent performance advantages. Specifically, the main academic contributions of this paper are as follows:
  
  First, for two different scenarios of large and small k values, this paper deeply expands the RadixSelect algorithm, and designs and implements a Top-k operator in combination with the unique architecture and instruction set of DLP-M. This effectively broadens the boundaries and possibilities of Top-k query methods on domestic AI processors. Empirical studies show that when the data volume reaches a relatively large scale, this algorithm demonstrates more excellent performance compared with the original implementation scheme, and has achieved remarkable results in terms of efficiency improvement.
  
  Second, deeply rooted in the architecture of domestic AI processors, this paper comprehensively optimizes the RadixSelect parallel algorithm. By fully exploiting the hardware acceleration potential and vectorization instruction advantages of the DLP-M processor, efficient parallel acceleration is achieved. At the same time, fine-grained optimizations are carried out from multiple dimensions such as the parallelism of bucket operations, memory access efficiency, and pipeline instructions, resulting in a significant increase in the algorithm throughput. When dealing with a relatively large scale of data, its performance has approached that of the NVIDIA A100 GPU, reaching the industry's leading level, and setting a new benchmark for the application of domestic processors in this field.
  
  Third, focusing on the actual application requirements of deep learning models, this paper conducts functional verification research. In order to effectively test the effect of the algorithm in real application scenarios, this paper carefully designs accuracy tests and performance tests. And it cleverly combines with the Pytorch deep learning framework to integrate the optimized Top-k operator into the neural network for the verification of the availability of training and inference. The experimental data shows that its accuracy is at a comparable level to the benchmark method, providing an innovative solution and practical path for the efficient solution of the Top-k query problem in deep learning tasks.
  
  In conclusion, the efficient Top-k query algorithm based on the DLP-M series processors proposed in this paper, with its accurate grasp of hardware characteristics and customized optimization strategies, has successfully achieved a qualitative leap in the efficiency of Top-k operations in deep learning tasks. It has opened up new horizons and directions for the academic and industrial circles in the efficient processing of Top-k query problems with massive data, and has important theoretical and practical significance.
\end{abstract*}
